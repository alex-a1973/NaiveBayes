{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.feature_selection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get column names\n",
    "def get_column_names():\n",
    "    \"\"\"\n",
    "    Get list of column names from UCI provided .names file\n",
    "    Input:\n",
    "        N/A\n",
    "    Output:\n",
    "        A list of column names for the dataset\n",
    "    \"\"\"\n",
    "    file = open(os.path.join(INPUT_DIR, 'spambase.names'), 'r')\n",
    "    result = []\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if (not line):\n",
    "            break\n",
    "        else:\n",
    "            if (line.startswith('word_freq_') or (line.startswith('char_freq_')) or (line.startswith('capital_run'))):\n",
    "                line = line.split(':')\n",
    "                result.append(line[0])\n",
    "    result.append('Target')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot ROC curve\n",
    "def plot_roc_curve(fpr, tpr, title=None):\n",
    "    plt.title(title)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Implementing a naive Bayes\n",
    "# We want to implement a regularized form of naive Bayes where a missing\n",
    "# feature does not hinder the computation\n",
    "\n",
    "# A) Read the input in the input directory and do test_train_split within\n",
    "# the notebook (5 points)\n",
    "\n",
    "# Get working directory path\n",
    "PWD = os.getcwd()\n",
    "# Get input directory path\n",
    "INPUT_DIR = os.path.join(PWD, 'input')\n",
    "# Get dataset path\n",
    "DATASET_PATH = os.path.join(INPUT_DIR, 'spambase.csv')\n",
    "# Get column names\n",
    "col_names = get_column_names()\n",
    "# Read data\n",
    "data = pd.read_csv(DATASET_PATH, names=col_names)\n",
    "# Get 'Target' column\n",
    "labels = pd.DataFrame(data.pop('Target'))\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Preprocess any data more than what you needed to do in Part 1 for\n",
    "# your own implementation of naive Bayes. Any assumptions should be \n",
    "# documented here (10 points)\n",
    "\n",
    "# I will use the top 10 and bottom 10 columns based off their positive and\n",
    "# negative correlation to the label column\n",
    "top_and_bottom_10_col_names = [\n",
    "    'word_freq_your',\n",
    "    'word_freq_000',\n",
    "    'word_freq_remove',\n",
    "    'char_freq_$',\n",
    "    'char_freq_!',\n",
    "    'word_freq_business',\n",
    "    'word_freq_you',\n",
    "    'word_freq_our',\n",
    "    'capital_run_length_total',\n",
    "    'word_freq_free',\n",
    "    'word_freq_technology',\n",
    "    'word_freq_re',\n",
    "    'word_freq_85',\n",
    "    'word_freq_edu',\n",
    "    'word_freq_650',\n",
    "    'word_freq_labs',\n",
    "    'word_freq_1999',\n",
    "    'word_freq_george',\n",
    "    'word_freq_hpl',\n",
    "    'word_freq_hp'\n",
    "]\n",
    "# New column bins thru visual analysis\n",
    "top_and_bottom_10_bins = [\n",
    "    [0, 3, 6, 12],\n",
    "    [0, 1, 6],\n",
    "    [0, 3, 8],\n",
    "    [0, 1, 2, 7],\n",
    "    [0, 1, 4, 33],\n",
    "    [0, 1, 2, 8],\n",
    "    [0, 1, 5, 19],\n",
    "    [0, 2, 5, 11],\n",
    "    [0, 10, 15842],\n",
    "    [0, 2, 21],\n",
    "    [0, 1, 5, 8],\n",
    "    [0, 10, 22],\n",
    "    [0, 1, 10, 21],\n",
    "    [0, 1, 10 , 23],\n",
    "    [0, 1, 3, 10],\n",
    "    [0, 1, 3, 6],\n",
    "    [0, 1, 3, 7],\n",
    "    [0, 1, 2, 34],\n",
    "    [0, 1, 17],\n",
    "    [0, 1, 21]\n",
    "]\n",
    "# New column discretized labels\n",
    "top_and_bottom_10_labels = [\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['low', 'high'],\n",
    "    ['low', 'high'],\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['low', 'high'],\n",
    "    ['low', 'high'],\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['medium', 'high'],\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['low', 'medium', 'high'],\n",
    "    ['low', 'high'],\n",
    "    ['low', 'high']\n",
    "]\n",
    "# Change X_train and X_test columns\n",
    "X_train = X_train[top_and_bottom_10_col_names]\n",
    "X_test = X_test[top_and_bottom_10_col_names]\n",
    "\n",
    "# Discretize all continuous columns\n",
    "for i in range(len(top_and_bottom_10_col_names)):\n",
    "    # Get current column name\n",
    "    col_name = top_and_bottom_10_col_names[i]\n",
    "    # Get associated bins for column\n",
    "    col_bins = top_and_bottom_10_bins[i]\n",
    "    # Get associated labels for bins\n",
    "    col_label = top_and_bottom_10_labels[i]\n",
    "    # Discretize X_train\n",
    "    X_train[col_name] = pd.cut(X_train[col_name], col_bins, labels=col_label, right=False)\n",
    "    # Discretize X_test\n",
    "    X_test[col_name] = pd.cut(X_test[col_name], col_bins, labels=col_label, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) Code to implement naive Bayes with any exception handling. Any\n",
    "# parameters considered import should be passed to the function call such\n",
    "# that parameter tuning can be done by the data scientist while trying \n",
    "# your function (35 points)\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Creates a NaiveBayes object\n",
    "        Input:\n",
    "            N/A\n",
    "        Output:\n",
    "            N/A\n",
    "        Initialization:\n",
    "            self.word_proba: Initialize a DataFrame which keeps attribute values as columns\n",
    "and probabilites of that attribute value being spam as one row and ham as another (i.e., \n",
    "P(word_freq_free_a_i|spam): word_freq_free_a_i, P(word_freq_free_a_i|not spam): word_freq_free_a_i)\n",
    "            self.pos_prior: Initialize prior probabilities of positive instances to None\n",
    "            self.neg_prior: Initialize prior probabilities of negative instances to None\n",
    "            self.true_neg: Initialize true negative value\n",
    "            self.true_pos: Initialize true positive value\n",
    "            self.false_neg: Initialize false negative value\n",
    "            self.false_pos: Initialize false positive value\n",
    "            self.confusion_matrix: Initialize beginning of 2D matrix (a.k.a confusion matrix)\n",
    "            self.preds: Initialize 1D array of length equal to testing set which holds predictions\n",
    "            self.pred_probas: Initialize beginning of 2D matrix containing 1D arrays a length k\n",
    "where k equals the set of values in label column and they contain the probability that the instance\n",
    "belongs to class label k (range of values for k, 0 <= i <= k-1)\n",
    "        \"\"\"\n",
    "        self.word_proba = pd.DataFrame()\n",
    "        self.pos_prior = None\n",
    "        self.neg_prior = None\n",
    "        self.true_neg = 0\n",
    "        self.true_pos = 0\n",
    "        self.false_neg = 0\n",
    "        self.false_pos = 0\n",
    "        self.confusion_matrix = []\n",
    "        self.preds = []\n",
    "        self.pred_probas = []\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Calculates prior probabilities, and probabilites of every attribute and their values\n",
    "        given all k class labels (i.e., binary classification, k = 2)\n",
    "        Input:\n",
    "            X_train: Dataset to train on\n",
    "            y_train: X_train's corresponding labels\n",
    "        Output:\n",
    "            N/A\n",
    "            Populates a DataFrame with probabilities explained above\n",
    "        \"\"\"\n",
    "        # If X_train is not an instance of a DataFrame\n",
    "        if (not(isinstance(X_train, pd.DataFrame))):\n",
    "            raise Exception('X_train is not of type \\'pd.DataFrame\\'')\n",
    "            \n",
    "        if (not(isinstance(y_train, pd.DataFrame)) and not(isinstance(y_train, pd.Series))):\n",
    "            raise Exception('y_train is not of type \\'pd.DataFrame\\' or \\'pd.Series\\'')\n",
    "            \n",
    "        # Get the column name of the class column \n",
    "        class_col_label = y_train.columns[0]\n",
    "        # Get number of spam and ham instances\n",
    "        class_freq = y_train[class_col_label].value_counts()\n",
    "        num_spam = class_freq[1]\n",
    "        num_ham = class_freq[0]\n",
    "        # Get prior probabilities\n",
    "        self.pos_prior, self.neg_prior = self._class_priors(num_spam, num_ham)\n",
    "        # Get conditional probabilities\n",
    "        self._get_conditional_probs(X_train, y_train, num_spam, num_ham)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Returns a vector of size m x 1 where m equals the length of X_test. The\n",
    "        vector consists of predictions on X_test with k unique values (k being the\n",
    "        number of classes we're dealing with)\n",
    "        \n",
    "        Input:\n",
    "            X_test: The testing set to make class predictions on\n",
    "        Output:\n",
    "            self.preds: A vector of class predictions our model made\n",
    "            self.true_neg: Counts amounts of true negatives and assigns them to self.true_neg\n",
    "            self.true_pos: Counts amounts of true positives and assigns them to self.true_pos\n",
    "            self.false_neg: Counts amounts of false negatives and assigns them to self.false_neg\n",
    "            self.false_pos: Counts amounts of false positives and assigns them to self.false_pos\n",
    "        \"\"\"\n",
    "        # Exception handling\n",
    "        if (not(isinstance(X_test, pd.DataFrame))):\n",
    "            raise Exception('X_test is not of type \\'pd.DataFrame\\'')\n",
    "            \n",
    "        # Predictions data structure was already filled\n",
    "        if (len(self.preds) != 0):\n",
    "            self.preds = []\n",
    "        \n",
    "        # Get column names of 'X_test'\n",
    "        col_names = X_test.columns.tolist()\n",
    "        # Iterate over every row in 'X_test'\n",
    "        for index, row in X_test.iterrows():\n",
    "            # Calculate the Naive Bayes Classifier formula for spam and ham class labels\n",
    "            ham_proba = self.neg_prior\n",
    "            spam_proba = self.pos_prior\n",
    "            # Iterate over every column to get correct column name to look in 'self.word_proba'\n",
    "            for col_name in col_names:\n",
    "                # Get value in current column name and current row in 'X_test'\n",
    "                row_col_value = row[col_name]\n",
    "                # Concatenate to get correct column name for 'self.word_proba'\n",
    "                proba_col_name = str(col_name + '_' + row_col_value)\n",
    "                # Get probability P(a_i|Not Spam)\n",
    "                row_col_val_ham = self.word_proba[proba_col_name][0]\n",
    "                # Get probability P(a_i|Spam)\n",
    "                row_col_val_spam = self.word_proba[proba_col_name][1]\n",
    "                # Multiply both probabilities with respective 'ham_proba' and 'spam_proba'\n",
    "                ham_proba *= row_col_val_ham\n",
    "                spam_proba *= row_col_val_spam\n",
    "            # See which accumulated probability is larger\n",
    "            if (ham_proba > spam_proba):\n",
    "                # 'ham_proba' is greater than 'spam_proba', so append 0 to 'self.preds'\n",
    "                self.preds.append(0)\n",
    "            else:\n",
    "                # 'spam_proba' is greater than 'ham_proba', so append 0 to 'self.preds'\n",
    "                self.preds.append(1)\n",
    "        return self.preds\n",
    "    \n",
    "    def predict_probas(self, X_test):\n",
    "        \"\"\"\n",
    "        Returns a matrix of size m x k where m equals the length of X_test and k\n",
    "        is the number of classes we are dealing with (i.e., for binary classification\n",
    "        k = 2). This matrix consists of probabilities for each instance of X_test \n",
    "        being belonging to each class k\n",
    "        \n",
    "        Input:\n",
    "            X_test: The testing set to make prediction of probabilities on\n",
    "        Output:\n",
    "            self.pred_probas: A matrix of size m x k which consists of probabilites\n",
    "for each instance of X_test belonging to class k\n",
    "        \"\"\"\n",
    "        # Exception handling\n",
    "        if (not(isinstance(X_test, pd.DataFrame))):\n",
    "            raise Exception('X_test is not of type \\'pd.DataFrame\\'')\n",
    "            \n",
    "        # Probabilities data structure was already filled\n",
    "        if (len(self.pred_probas) != 0):\n",
    "            self.pred_probas = []\n",
    "        \n",
    "        # Get column names of 'X_test'\n",
    "        col_names = X_test.columns.tolist()\n",
    "        # Iterate over every row in 'X_test'\n",
    "        for index, row in X_test.iterrows():\n",
    "            # Probabilities to store each respective probability in\n",
    "            probas = []\n",
    "            # Calculate the Naive Bayes Classifier formula for spam and ham class labels\n",
    "            ham_proba = self.neg_prior\n",
    "            spam_proba = self.pos_prior\n",
    "            # Iterate over every column to get correct column name to look in 'self.word_proba'\n",
    "            for col_name in col_names:\n",
    "                # Get value in current column name and current row in 'X_test'\n",
    "                row_col_value = row[col_name]\n",
    "                # Concatenate to get correct column name for 'self.word_proba'\n",
    "                proba_col_name = str(col_name + '_' + row_col_value)\n",
    "                # Get probability P(a_i|Not Spam)\n",
    "                row_col_val_ham = self.word_proba[proba_col_name][0]\n",
    "                # Get probability P(a_i|Spam)\n",
    "                row_col_val_spam = self.word_proba[proba_col_name][1]\n",
    "                # Multiply both probabilities with respective 'ham_proba' and 'spam_proba'\n",
    "                ham_proba *= row_col_val_ham\n",
    "                spam_proba *= row_col_val_spam\n",
    "            # Get sums of both probabilities\n",
    "            ham_spam_proba_sum = ham_proba + spam_proba\n",
    "            # Get actual percentage value of 'ham_proba' and 'spam_proba' and store them in 'probas'\n",
    "            ham_proba /= ham_spam_proba_sum\n",
    "            spam_proba /= ham_spam_proba_sum\n",
    "            # Append 'ham_proba' and 'spam_proba' to 'probas'\n",
    "            probas.append(ham_proba)\n",
    "            probas.append(spam_proba)\n",
    "            # Append array to 'self.pred_probas' array\n",
    "            self.pred_probas.append(probas)\n",
    "        return self.pred_probas\n",
    "                \n",
    "    def get_metrics(self, predictions, y_test):\n",
    "        \"\"\"\n",
    "        Initialize metrics of this class such as self.true_neg, self.true_pos, \n",
    "self.false_neg, self.false_pos, and self.confusion_matrix. Also return such metrics\n",
    "and all this being tested against the ground truths of y_test\n",
    "        Input:\n",
    "            predictions: The predictions previously acquired by running 'predict' method\n",
    "            y_test: Ground truths to be compared against\n",
    "        Output:\n",
    "            self.true_neg: The true negative value\n",
    "            self.true_pos: The true positive value\n",
    "            self.false_neg: The false negative value\n",
    "            self.false_pos: The false positive value\n",
    "            self.confusion_matrix: The confusion matrix comprised of TN, TP, FN, FP\n",
    "        \"\"\"\n",
    "        # Handling exceptions\n",
    "        if (len(predictions) == 0):\n",
    "            raise Exception('You have not run \\'predict\\' method previously and do not have a list of predictions')\n",
    "        \n",
    "        if (not(isinstance(y_test, pd.DataFrame))):\n",
    "            raise Exception('X_test is not of type \\'pd.DataFrame\\'')\n",
    "        \n",
    "        # Get class column label\n",
    "        class_col_name = y_test.columns[0]\n",
    "        # Select label column and convert the data structure to a list\n",
    "        labels = y_test[class_col_name].tolist()\n",
    "        # Iterate over both lists checking each entry against each other\n",
    "        for i in range(len(predictions)):\n",
    "            if (predictions[i] == 0 and labels[i] == 0):\n",
    "                # True negative case\n",
    "                self.true_neg += 1\n",
    "            elif (predictions[i] == 1 and labels[i] == 1):\n",
    "                # True positive case\n",
    "                self.true_pos += 1\n",
    "            elif (predictions[i] == 0 and labels[i] == 1):\n",
    "                # False negative case\n",
    "                self.false_neg += 1\n",
    "            elif (predictions[i] == 1 and labels[i] == 0):\n",
    "                # False positive case\n",
    "                self.false_pos += 1\n",
    "        # Populate 'self.confusion_matrix'\n",
    "        self.confusion_matrix = [[self.true_neg, self.false_pos], [self.false_neg, self.true_pos]]\n",
    "        return self.true_neg, self.true_pos, self.false_neg, self.false_pos, self.confusion_matrix\n",
    "    \n",
    "    def _class_priors(self, num_spam, num_ham):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            num_spam: Number of spam messages\n",
    "            num_ham: Number of ham messages\n",
    "        Output:\n",
    "            pos_prior: The prior probabilities of the positive examples given y\n",
    "            neg_prior: The prior probabilities of the negative examples given y\n",
    "        \"\"\" \n",
    "        total_len = num_spam + num_ham\n",
    "        pos_prior = num_spam / total_len\n",
    "        neg_prior = num_ham / total_len\n",
    "        return pos_prior, neg_prior\n",
    "    \n",
    "    def _get_conditional_probs(self, X, y, num_spam, num_ham):\n",
    "        \"\"\"\n",
    "        Populates self.word_proba with conditional probabilities of every attributes\n",
    "        values according to different set of class values\n",
    "        \"\"\"\n",
    "        # Copy the X dataset\n",
    "        data = X.copy()\n",
    "        # Get class column label\n",
    "        class_col_name = y.columns[0]\n",
    "        # Get list of unique class values\n",
    "        class_uniques = list(y[class_col_name].unique())\n",
    "        # Concatenate the class label column to the copy\n",
    "        data[class_col_name] = y[class_col_name]\n",
    "        # Initialize 'self.word_proba' with correct column and row labels\n",
    "        self._initialize_word_proba_ds(X, y)\n",
    "        # Get column names of 'data'\n",
    "        col_names = data.columns.tolist()\n",
    "        # Iterate over every column calculating conditional probabilities\n",
    "        for col_name in col_names:\n",
    "            # Disregard the 'class_col_name' column\n",
    "            if (col_name == class_col_name):\n",
    "                continue\n",
    "                \n",
    "            # Get attribute values for current attribute/column\n",
    "            uniques = list(data[col_name].unique())\n",
    "            # Iterate over the set of attribute values\n",
    "            for attrib_value in uniques:\n",
    "                # Select column name to populate wrt 'self.word_proba' column naming\n",
    "                proba_col_name = str(col_name + '_' + attrib_value)\n",
    "                # Iterate over set of class values to get probability wrt a class label\n",
    "                for class_value in class_uniques:\n",
    "                    # Get frequency of 'attrib_value'\n",
    "                    attrib_value_freq = len(data.loc[(data[col_name] == attrib_value) & (data[class_col_name] == class_value), col_name])\n",
    "                    # Put frequency divided by number of spam or ham instances into appropriate column and row\n",
    "                    if (class_value == 0):\n",
    "                        # 'class_value' is equal to ham (0) so divide by 'num_ham'\n",
    "                        self.word_proba[proba_col_name][class_value] = (attrib_value_freq / num_ham)\n",
    "                    else:\n",
    "                        # 'class_value' is equal to spam (1) so divide by 'num_spam'\n",
    "                        self.word_proba[proba_col_name][class_value] = (attrib_value_freq / num_spam)\n",
    "        \n",
    "    def _initialize_word_proba_ds(self, X, y):\n",
    "        \"\"\"\n",
    "        Initializes self.word_proba where all entries are zero and row and columns\n",
    "        are labeled correctly\n",
    "        \n",
    "        Input:\n",
    "            X: The dataset we train on\n",
    "            y: The associated labels\n",
    "        Output:\n",
    "            Initializes our data structure that holds are probabilities\n",
    "        \"\"\"\n",
    "        # Get X's columns\n",
    "        col_names = X.columns.tolist()\n",
    "        # Iterate over all columns in 'X'\n",
    "        for col_name in col_names:\n",
    "            # Get unique values for that column\n",
    "            uniques = list(X[col_name].unique())\n",
    "            # Iterate over all the unique values of current attribute\n",
    "            for attrib_value in uniques:\n",
    "                # Create column name by concatenating 'col_name' and 'attrib_value'\n",
    "                new_col_name = str(col_name + '_' + attrib_value)\n",
    "                # Append new column\n",
    "                self.word_proba[new_col_name] = None\n",
    "              \n",
    "        # Get class column label\n",
    "        y_col_name = y.columns[0]\n",
    "        # Get unique values for class label column\n",
    "        y_uniques = y[y_col_name].unique()\n",
    "        # Populate list of null values equal to the number of columns in 'self.word_proba'\n",
    "        dummy_values = []\n",
    "        for i in range(len(self.word_proba.columns)):\n",
    "            dummy_values.append(0)\n",
    "        # Create list of Series Pandas objects\n",
    "        list_of_series = []\n",
    "        # Iterate over unique values in class label column\n",
    "        for unique in y_uniques:\n",
    "            # Create Series object\n",
    "            series = pd.Series(dummy_values, index=self.word_proba.columns)\n",
    "            # Add 'series' to list of Series objects\n",
    "            list_of_series.append(series)\n",
    "        # Append the k number of unique class values to 'self.word_proba' data structure\n",
    "        self.word_proba = self.word_proba.append(list_of_series, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D) Is naive Bayes interpretable? Which words are more important for spam/\n",
    "# ham classification? Provide a visual feature analysis of your model\n",
    "# performance\n",
    "nb = NaiveBayes()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_your_low</th>\n",
       "      <th>word_freq_your_medium</th>\n",
       "      <th>word_freq_your_high</th>\n",
       "      <th>word_freq_000_low</th>\n",
       "      <th>word_freq_000_high</th>\n",
       "      <th>word_freq_remove_low</th>\n",
       "      <th>word_freq_remove_high</th>\n",
       "      <th>char_freq_$_low</th>\n",
       "      <th>char_freq_$_high</th>\n",
       "      <th>char_freq_$_medium</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_1999_low</th>\n",
       "      <th>word_freq_1999_medium</th>\n",
       "      <th>word_freq_1999_high</th>\n",
       "      <th>word_freq_george_low</th>\n",
       "      <th>word_freq_george_medium</th>\n",
       "      <th>word_freq_george_high</th>\n",
       "      <th>word_freq_hpl_low</th>\n",
       "      <th>word_freq_hpl_high</th>\n",
       "      <th>word_freq_hp_low</th>\n",
       "      <th>word_freq_hp_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.974408</td>\n",
       "      <td>0.0184834</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.000473934</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.000473934</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934123</td>\n",
       "      <td>0.0606635</td>\n",
       "      <td>0.00521327</td>\n",
       "      <td>0.820379</td>\n",
       "      <td>0.0720379</td>\n",
       "      <td>0.107583</td>\n",
       "      <td>0.858294</td>\n",
       "      <td>0.141706</td>\n",
       "      <td>0.753555</td>\n",
       "      <td>0.246445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.896269</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00373134</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>0.0776119</td>\n",
       "      <td>0.995522</td>\n",
       "      <td>0.00447761</td>\n",
       "      <td>0.984328</td>\n",
       "      <td>0.00373134</td>\n",
       "      <td>0.0119403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98209</td>\n",
       "      <td>0.0149254</td>\n",
       "      <td>0.00298507</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.000746269</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995522</td>\n",
       "      <td>0.00447761</td>\n",
       "      <td>0.99403</td>\n",
       "      <td>0.00597015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  word_freq_your_low word_freq_your_medium word_freq_your_high  \\\n",
       "0           0.974408             0.0184834            0.007109   \n",
       "1           0.896269                   0.1          0.00373134   \n",
       "\n",
       "  word_freq_000_low word_freq_000_high word_freq_remove_low  \\\n",
       "0          0.999526        0.000473934             0.999526   \n",
       "1          0.922388          0.0776119             0.995522   \n",
       "\n",
       "  word_freq_remove_high char_freq_$_low char_freq_$_high char_freq_$_medium  \\\n",
       "0           0.000473934               1                0                  0   \n",
       "1            0.00447761        0.984328       0.00373134          0.0119403   \n",
       "\n",
       "   ... word_freq_1999_low word_freq_1999_medium word_freq_1999_high  \\\n",
       "0  ...           0.934123             0.0606635          0.00521327   \n",
       "1  ...            0.98209             0.0149254          0.00298507   \n",
       "\n",
       "  word_freq_george_low word_freq_george_medium word_freq_george_high  \\\n",
       "0             0.820379               0.0720379              0.107583   \n",
       "1             0.999254             0.000746269                     0   \n",
       "\n",
       "  word_freq_hpl_low word_freq_hpl_high word_freq_hp_low word_freq_hp_high  \n",
       "0          0.858294           0.141706         0.753555          0.246445  \n",
       "1          0.995522         0.00447761          0.99403        0.00597015  \n",
       "\n",
       "[2 rows x 53 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visual display of training phase of the model\n",
    "nb.word_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negatives: 534\n",
      "True positive: 385\n",
      "False negatives: 88\n",
      "False positive: 144\n",
      "Confusion matrix: [[534, 144], [88, 385]]\n",
      "--------------------------------------\n",
      "Accuracy: 0.7984361424847958\n",
      "Precision: 0.7277882797731569\n",
      "Recall: 0.813953488372093\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# E) Output a confusion matrix from the constructed tree on the test set.\n",
    "# Compute accuracy, precision, recall and obtain an AUC plot of the \n",
    "# classifier (you don't have to code the plotting functions). You can \n",
    "# reuse any library but you have to output the data in a way that the\n",
    "# plotting function can be invoked (10 points)\n",
    "\n",
    "# Get list of predictions\n",
    "preds = nb.predict(X_test)\n",
    "# Get 2D Matrix of probabilities of predictions\n",
    "pred_probas = nb.predict_probas(X_test)\n",
    "# Convert to numpy.ndarray\n",
    "np_pred_probas = np.array(pred_probas, np.float64)\n",
    "# Get spam probabilities\n",
    "pos_probas = np_pred_probas[:, 1]\n",
    "# Get confusion matrix, precision, and recall\n",
    "true_neg, true_pos, false_neg, false_pos, confusion_matrix = nb.get_metrics(preds, y_test)\n",
    "print(f'True negatives: {true_neg}')\n",
    "print(f'True positive: {true_pos}')\n",
    "print(f'False negatives: {false_neg}')\n",
    "print(f'False positive: {false_pos}')\n",
    "print(f'Confusion matrix: {confusion_matrix}')\n",
    "print('--------------------------------------')\n",
    "print(f'Accuracy: {(true_neg + true_pos)/(true_neg + true_pos + false_neg + false_pos)}')\n",
    "print(f'Precision: {(true_pos)/(true_pos + false_pos)}')\n",
    "print(f'Recall: {(true_pos)/(true_pos + false_neg)}')\n",
    "print('--------------------------------------')\n",
    "\n",
    "# Plot the two AUCs\n",
    "nb_fpr, nb_tpr, nb_thresholds = roc_curve(y_test, pos_probas)\n",
    "plot_roc_curve(nb_fpr, nb_tpr, \"Naive Bayes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
