{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"NaiveBayes.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"ywfVBC9_VpXE"},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.model_selection import *\n","from sklearn.metrics import *\n","from sklearn.preprocessing import *\n","from sklearn.feature_selection import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TgN-jeRQVpXU"},"source":["# Function to get column names\n","def get_column_names():\n","    \"\"\"\n","    Get list of column names from UCI provided .names file\n","    Input:\n","        N/A\n","    Output:\n","        A list of column names for the dataset\n","    \"\"\"\n","    file = open(os.path.join(INPUT_DIR, 'spambase.names'), 'r')\n","    result = []\n","    while True:\n","        line = file.readline()\n","        if (not line):\n","            break\n","        else:\n","            if (line.startswith('word_freq_') or (line.startswith('char_freq_')) or (line.startswith('capital_run'))):\n","                line = line.split(':')\n","                result.append(line[0])\n","    result.append('Target')\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"os_UWnLYVpXV"},"source":["# Function to plot ROC curve\n","def plot_roc_curve(fpr, tpr, title=None):\n","    plt.title(title)\n","    plt.plot(fpr, tpr)\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.axis([0, 1, 0, 1])\n","    plt.xlabel('False positive rate')\n","    plt.ylabel('True positive rate')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ie1naYGaVpXW"},"source":["# Implementing a naive Bayes\n","# We want to implement a regularized form of naive Bayes where a missing\n","# feature does not hinder the computation\n","\n","# A) Read the input in the input directory and do test_train_split within\n","# the notebook (5 points)\n","\n","# Get working directory path\n","PWD = os.getcwd()\n","# Get input directory path\n","INPUT_DIR = os.path.join(PWD, 'input')\n","# Get dataset path\n","DATASET_PATH = os.path.join(INPUT_DIR, 'spambase.csv')\n","# Get column names\n","col_names = get_column_names()\n","# Read data\n","data = pd.read_csv(DATASET_PATH, names=col_names)\n","# Get 'Target' column\n","labels = pd.DataFrame(data.pop('Target'))\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(data, labels, random_state=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2vuQcL0RVpXX","outputId":"07749e89-f8cb-4ac7-eb0c-234d7bbd6611"},"source":["# Select 'k' amount of features and categorize them\n","def select_k_best_features(X, y, k):\n","    feature_names = X.columns.tolist()\n","    selector = SelectKBest(chi2, k=k)\n","    selector.fit(X, y)\n","    mask = selector.get_support()\n","    new_features = []\n","    for boolean, feature in zip(mask, feature_names):\n","        if boolean:\n","            new_features.append(feature)\n","    X_out = selector.transform(X)\n","    return pd.DataFrame(X_out, index=X.index, columns=new_features)\n","\n","def select_k_bins(X, k):\n","    est = KBinsDiscretizer(n_bins=k, encode='ordinal', strategy='uniform')\n","    X_out = est.fit_transform(X)\n","    return pd.DataFrame(X_out, index=X.index, columns=X.columns)\n","temp = select_k_best_features(X_train, y_train, 10)\n","temp = select_k_bins(temp, 3)\n","temp.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word_freq_remove</th>\n","      <th>word_freq_free</th>\n","      <th>word_freq_your</th>\n","      <th>word_freq_hp</th>\n","      <th>word_freq_hpl</th>\n","      <th>word_freq_george</th>\n","      <th>char_freq_!</th>\n","      <th>capital_run_length_average</th>\n","      <th>capital_run_length_longest</th>\n","      <th>capital_run_length_total</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3051</th>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.61</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.327</td>\n","      <td>1.068</td>\n","      <td>2.0</td>\n","      <td>47.0</td>\n","    </tr>\n","    <tr>\n","      <th>3349</th>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>2.000</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>3529</th>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>2.500</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>1505</th>\n","      <td>0.23</td>\n","      <td>0.0</td>\n","      <td>3.30</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.289</td>\n","      <td>6.529</td>\n","      <td>276.0</td>\n","      <td>666.0</td>\n","    </tr>\n","    <tr>\n","      <th>2718</th>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.64</td>\n","      <td>1.28</td>\n","      <td>0.64</td>\n","      <td>1.92</td>\n","      <td>0.225</td>\n","      <td>1.902</td>\n","      <td>12.0</td>\n","      <td>78.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      word_freq_remove  word_freq_free  word_freq_your  word_freq_hp  \\\n","3051              0.00             0.0            0.61          0.00   \n","3349              0.00             0.0            0.00          0.00   \n","3529              0.00             0.0            0.00          0.00   \n","1505              0.23             0.0            3.30          0.00   \n","2718              0.00             0.0            0.64          1.28   \n","\n","      word_freq_hpl  word_freq_george  char_freq_!  \\\n","3051           0.00              0.00        0.327   \n","3349           0.00              0.00        0.000   \n","3529           0.00              0.00        0.000   \n","1505           0.00              0.00        1.289   \n","2718           0.64              1.92        0.225   \n","\n","      capital_run_length_average  capital_run_length_longest  \\\n","3051                       1.068                         2.0   \n","3349                       2.000                         4.0   \n","3529                       2.500                         4.0   \n","1505                       6.529                       276.0   \n","2718                       1.902                        12.0   \n","\n","      capital_run_length_total  \n","3051                      47.0  \n","3349                       6.0  \n","3529                       5.0  \n","1505                     666.0  \n","2718                      78.0  "]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"hAa3_KVuVpXZ"},"source":["# I will use the top 10 and bottom 10 columns based off their positive and\n","# negative correlation to the label column\n","top_and_bottom_10_col_names = [\n","    'word_freq_your',\n","    'word_freq_000',\n","    'word_freq_remove',\n","    'char_freq_$',\n","    'char_freq_!',\n","    'word_freq_business',\n","    'word_freq_you',\n","    'word_freq_our',\n","    'capital_run_length_total',\n","    'word_freq_free',\n","    'word_freq_technology',\n","    'word_freq_re',\n","    'word_freq_85',\n","    'word_freq_edu',\n","    'word_freq_650',\n","    'word_freq_labs',\n","    'word_freq_1999',\n","    'word_freq_george',\n","    'word_freq_hpl',\n","    'word_freq_hp'\n","]\n","\n","# New column bins thru visual analysis\n","top_and_bottom_10_bins = [\n","    [0, 3, 6, 12],\n","    [0, 1, 6],\n","    [0, 3, 8],\n","    [0, 1, 2, 7],\n","    [0, 1, 4, 33],\n","    [0, 1, 2, 8],\n","    [0, 1, 5, 19],\n","    [0, 2, 5, 11],\n","    [0, 10, 15842],\n","    [0, 2, 21],\n","    [0, 1, 5, 8],\n","    [0, 10, 22],\n","    [0, 1, 10, 21],\n","    [0, 1, 10 , 23],\n","    [0, 1, 3, 10],\n","    [0, 1, 3, 6],\n","    [0, 1, 3, 7],\n","    [0, 1, 2, 34],\n","    [0, 1, 17],\n","    [0, 1, 21]\n","]\n","\n","# New column discretized labels (chosen completely by my discretion)\n","top_and_bottom_10_labels = [\n","    ['low', 'medium', 'high'],\n","    ['low', 'high'],\n","    ['low', 'high'],\n","    ['low', 'medium', 'high'],\n","    ['low', 'medium', 'high'],\n","    ['low', 'medium', 'high'],\n","    ['low', 'medium', 'high'],\n","    ['low', 'medium', 'high'],\n","    ['low', 'high'],\n","    ['low', 'high'],\n","    ['low', 'medium', 'high'],\n","    ['medium', 'high'],\n","    ['low', 'medium', 'high'],\n","    ['low', 'medium', 'high'],\n","    ['low', 'medium', 'high'],\n","    ['low', 'medium', 'high'],\n","    ['low', 'medium', 'high'],\n","    ['low', 'medium', 'high'],\n","    ['low', 'high'],\n","    ['low', 'high']\n","]\n","# Change X_train and X_test columns\n","X_train = X_train[top_and_bottom_10_col_names]\n","X_test = X_test[top_and_bottom_10_col_names]\n","\n","# Discretize all continuous columns\n","for i in range(len(top_and_bottom_10_col_names)):\n","    # Get current column name\n","    col_name = top_and_bottom_10_col_names[i]\n","    # Get associated bins for column\n","    col_bins = top_and_bottom_10_bins[i]\n","    # Get associated labels for bins\n","    col_label = top_and_bottom_10_labels[i]\n","    # Discretize X_train\n","    X_train[col_name] = pd.cut(X_train[col_name], col_bins, labels=col_label, right=False)\n","    # Discretize X_test\n","    X_test[col_name] = pd.cut(X_test[col_name], col_bins, labels=col_label, right=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5nmSit9fVpXi"},"source":["# Code to implement naive Bayes with any exception handling.\n","class NaiveBayes:\n","    def __init__(self):\n","        \"\"\"\n","        Creates a NaiveBayes object\n","        Input:\n","            N/A\n","        Output:\n","            N/A\n","        Initialization:\n","            self.word_proba: Initialize a DataFrame which keeps attribute values as columns\n","and probabilites of that attribute value being spam as one row and ham as another (i.e., \n","P(word_freq_free_a_i|spam): word_freq_free_a_i, P(word_freq_free_a_i|not spam): word_freq_free_a_i)\n","            self.pos_prior: Initialize prior probabilities of positive instances to None\n","            self.neg_prior: Initialize prior probabilities of negative instances to None\n","            self.true_neg: Initialize true negative value\n","            self.true_pos: Initialize true positive value\n","            self.false_neg: Initialize false negative value\n","            self.false_pos: Initialize false positive value\n","            self.confusion_matrix: Initialize beginning of 2D matrix (a.k.a confusion matrix)\n","            self.preds: Initialize 1D array of length equal to testing set which holds predictions\n","            self.pred_probas: Initialize beginning of 2D matrix containing 1D arrays a length k\n","where k equals the set of values in label column and they contain the probability that the instance\n","belongs to class label k (range of values for k, 0 <= i <= k-1)\n","        \"\"\"\n","        self.word_proba = pd.DataFrame()\n","        self.pos_prior = None\n","        self.neg_prior = None\n","        self.true_neg = 0\n","        self.true_pos = 0\n","        self.false_neg = 0\n","        self.false_pos = 0\n","        self.confusion_matrix = []\n","        self.preds = []\n","        self.pred_probas = []\n","    \n","    def fit(self, X_train, y_train):\n","        \"\"\"\n","        Calculates prior probabilities, and probabilites of every attribute and their values\n","        given all k class labels (i.e., binary classification, k = 2)\n","        Input:\n","            X_train: Dataset to train on\n","            y_train: X_train's corresponding labels\n","        Output:\n","            N/A\n","            Populates a DataFrame with probabilities explained above\n","        \"\"\"\n","        # If X_train is not an instance of a DataFrame\n","        if (not(isinstance(X_train, pd.DataFrame))):\n","            raise Exception('X_train is not of type \\'pd.DataFrame\\'')\n","            \n","        if (not(isinstance(y_train, pd.DataFrame)) and not(isinstance(y_train, pd.Series))):\n","            raise Exception('y_train is not of type \\'pd.DataFrame\\' or \\'pd.Series\\'')\n","            \n","        # Get the column name of the class column \n","        class_col_label = y_train.columns[0]\n","        # Get number of spam and ham instances\n","        class_freq = y_train[class_col_label].value_counts()\n","        num_spam = class_freq[1]\n","        num_ham = class_freq[0]\n","        # Get prior probabilities\n","        self.pos_prior, self.neg_prior = self._class_priors(num_spam, num_ham)\n","        # Get conditional probabilities\n","        self._get_conditional_probs(X_train, y_train, num_spam, num_ham)\n","    \n","    def predict(self, X_test):\n","        \"\"\"\n","        Returns a vector of size m x 1 where m equals the length of X_test. The\n","        vector consists of predictions on X_test with k unique values (k being the\n","        number of classes we're dealing with)\n","        \n","        Input:\n","            X_test: The testing set to make class predictions on\n","        Output:\n","            self.preds: A vector of class predictions our model made\n","            self.true_neg: Counts amounts of true negatives and assigns them to self.true_neg\n","            self.true_pos: Counts amounts of true positives and assigns them to self.true_pos\n","            self.false_neg: Counts amounts of false negatives and assigns them to self.false_neg\n","            self.false_pos: Counts amounts of false positives and assigns them to self.false_pos\n","        \"\"\"\n","        # Exception handling\n","        if (not(isinstance(X_test, pd.DataFrame))):\n","            raise Exception('X_test is not of type \\'pd.DataFrame\\'')\n","            \n","        # Predictions data structure was already filled\n","        if (len(self.preds) != 0):\n","            self.preds = []\n","        \n","        # Get column names of 'X_test'\n","        col_names = X_test.columns.tolist()\n","        # Iterate over every row in 'X_test'\n","        for index, row in X_test.iterrows():\n","            # Calculate the Naive Bayes Classifier formula for spam and ham class labels\n","            ham_proba = self.neg_prior\n","            spam_proba = self.pos_prior\n","            # Iterate over every column to get correct column name to look in 'self.word_proba'\n","            for col_name in col_names:\n","                # Get value in current column name and current row in 'X_test'\n","                row_col_value = row[col_name]\n","                # Concatenate to get correct column name for 'self.word_proba'\n","                proba_col_name = str(col_name + '_' + row_col_value)\n","                # Get probability P(a_i|Not Spam)\n","                row_col_val_ham = self.word_proba[proba_col_name][0]\n","                # Get probability P(a_i|Spam)\n","                row_col_val_spam = self.word_proba[proba_col_name][1]\n","                # Multiply both probabilities with respective 'ham_proba' and 'spam_proba'\n","                ham_proba *= row_col_val_ham\n","                spam_proba *= row_col_val_spam\n","            # See which accumulated probability is larger\n","            if (ham_proba > spam_proba):\n","                # 'ham_proba' is greater than 'spam_proba', so append 0 to 'self.preds'\n","                self.preds.append(0)\n","            else:\n","                # 'spam_proba' is greater than 'ham_proba', so append 0 to 'self.preds'\n","                self.preds.append(1)\n","        return self.preds\n","    \n","    def predict_probas(self, X_test):\n","        \"\"\"\n","        Returns a matrix of size m x k where m equals the length of X_test and k\n","        is the number of classes we are dealing with (i.e., for binary classification\n","        k = 2). This matrix consists of probabilities for each instance of X_test \n","        being belonging to each class k\n","        \n","        Input:\n","            X_test: The testing set to make prediction of probabilities on\n","        Output:\n","            self.pred_probas: A matrix of size m x k which consists of probabilites\n","for each instance of X_test belonging to class k\n","        \"\"\"\n","        # Exception handling\n","        if (not(isinstance(X_test, pd.DataFrame))):\n","            raise Exception('X_test is not of type \\'pd.DataFrame\\'')\n","            \n","        # Probabilities data structure was already filled\n","        if (len(self.pred_probas) != 0):\n","            self.pred_probas = []\n","        \n","        # Get column names of 'X_test'\n","        col_names = X_test.columns.tolist()\n","        # Iterate over every row in 'X_test'\n","        for index, row in X_test.iterrows():\n","            # Probabilities to store each respective probability in\n","            probas = []\n","            # Calculate the Naive Bayes Classifier formula for spam and ham class labels\n","            ham_proba = self.neg_prior\n","            spam_proba = self.pos_prior\n","            # Iterate over every column to get correct column name to look in 'self.word_proba'\n","            for col_name in col_names:\n","                # Get value in current column name and current row in 'X_test'\n","                row_col_value = row[col_name]\n","                # Concatenate to get correct column name for 'self.word_proba'\n","                proba_col_name = str(col_name + '_' + row_col_value)\n","                # Get probability P(a_i|Not Spam)\n","                row_col_val_ham = self.word_proba[proba_col_name][0]\n","                # Get probability P(a_i|Spam)\n","                row_col_val_spam = self.word_proba[proba_col_name][1]\n","                # Multiply both probabilities with respective 'ham_proba' and 'spam_proba'\n","                ham_proba *= row_col_val_ham\n","                spam_proba *= row_col_val_spam\n","            # Get sums of both probabilities\n","            ham_spam_proba_sum = ham_proba + spam_proba\n","            # Get actual percentage value of 'ham_proba' and 'spam_proba' and store them in 'probas'\n","            ham_proba /= ham_spam_proba_sum\n","            spam_proba /= ham_spam_proba_sum\n","            # Append 'ham_proba' and 'spam_proba' to 'probas'\n","            probas.append(ham_proba)\n","            probas.append(spam_proba)\n","            # Append array to 'self.pred_probas' array\n","            self.pred_probas.append(probas)\n","        return self.pred_probas\n","                \n","    def get_metrics(self, predictions, y_test):\n","        \"\"\"\n","        Initialize metrics of this class such as self.true_neg, self.true_pos, \n","self.false_neg, self.false_pos, and self.confusion_matrix. Also return such metrics\n","and all this being tested against the ground truths of y_test\n","        Input:\n","            predictions: The predictions previously acquired by running 'predict' method\n","            y_test: Ground truths to be compared against\n","        Output:\n","            self.true_neg: The true negative value\n","            self.true_pos: The true positive value\n","            self.false_neg: The false negative value\n","            self.false_pos: The false positive value\n","            self.confusion_matrix: The confusion matrix comprised of TN, TP, FN, FP\n","        \"\"\"\n","        # Handling exceptions\n","        if (len(predictions) == 0):\n","            raise Exception('You have not run \\'predict\\' method previously and do not have a list of predictions')\n","        \n","        if (not(isinstance(y_test, pd.DataFrame))):\n","            raise Exception('X_test is not of type \\'pd.DataFrame\\'')\n","        \n","        # Get class column label\n","        class_col_name = y_test.columns[0]\n","        # Select label column and convert the data structure to a list\n","        labels = y_test[class_col_name].tolist()\n","        # Iterate over both lists checking each entry against each other\n","        for i in range(len(predictions)):\n","            if (predictions[i] == 0 and labels[i] == 0):\n","                # True negative case\n","                self.true_neg += 1\n","            elif (predictions[i] == 1 and labels[i] == 1):\n","                # True positive case\n","                self.true_pos += 1\n","            elif (predictions[i] == 0 and labels[i] == 1):\n","                # False negative case\n","                self.false_neg += 1\n","            elif (predictions[i] == 1 and labels[i] == 0):\n","                # False positive case\n","                self.false_pos += 1\n","        # Populate 'self.confusion_matrix'\n","        self.confusion_matrix = [[self.true_neg, self.false_pos], [self.false_neg, self.true_pos]]\n","        return self.true_neg, self.true_pos, self.false_neg, self.false_pos, self.confusion_matrix\n","    \n","    def _class_priors(self, num_spam, num_ham):\n","        \"\"\"\n","        Input:\n","            num_spam: Number of spam messages\n","            num_ham: Number of ham messages\n","        Output:\n","            pos_prior: The prior probabilities of the positive examples given y\n","            neg_prior: The prior probabilities of the negative examples given y\n","        \"\"\" \n","        total_len = num_spam + num_ham\n","        pos_prior = num_spam / total_len\n","        neg_prior = num_ham / total_len\n","        return pos_prior, neg_prior\n","    \n","    def _get_conditional_probs(self, X, y, num_spam, num_ham):\n","        \"\"\"\n","        Populates self.word_proba with conditional probabilities of every attributes\n","        values according to different set of class values\n","        \"\"\"\n","        # Copy the X dataset\n","        data = X.copy()\n","        # Get class column label\n","        class_col_name = y.columns[0]\n","        # Get list of unique class values\n","        class_uniques = list(y[class_col_name].unique())\n","        # Concatenate the class label column to the copy\n","        data[class_col_name] = y[class_col_name]\n","        # Initialize 'self.word_proba' with correct column and row labels\n","        self._initialize_word_proba_ds(X, y)\n","        # Get column names of 'data'\n","        col_names = data.columns.tolist()\n","        # Iterate over every column calculating conditional probabilities\n","        for col_name in col_names:\n","            # Disregard the 'class_col_name' column\n","            if (col_name == class_col_name):\n","                continue\n","                \n","            # Get attribute values for current attribute/column\n","            uniques = list(data[col_name].unique())\n","            # Iterate over the set of attribute values\n","            for attrib_value in uniques:\n","                # Select column name to populate wrt 'self.word_proba' column naming\n","                proba_col_name = str(col_name + '_' + attrib_value)\n","                # Iterate over set of class values to get probability wrt a class label\n","                for class_value in class_uniques:\n","                    # Get frequency of 'attrib_value'\n","                    attrib_value_freq = len(data.loc[(data[col_name] == attrib_value) & (data[class_col_name] == class_value), col_name])\n","                    # Put frequency divided by number of spam or ham instances into appropriate column and row\n","                    if (class_value == 0):\n","                        # 'class_value' is equal to ham (0) so divide by 'num_ham'\n","                        self.word_proba[proba_col_name][class_value] = (attrib_value_freq / num_ham)\n","                    else:\n","                        # 'class_value' is equal to spam (1) so divide by 'num_spam'\n","                        self.word_proba[proba_col_name][class_value] = (attrib_value_freq / num_spam)\n","        \n","    def _initialize_word_proba_ds(self, X, y):\n","        \"\"\"\n","        Initializes self.word_proba where all entries are zero and row and columns\n","        are labeled correctly\n","        \n","        Input:\n","            X: The dataset we train on\n","            y: The associated labels\n","        Output:\n","            Initializes our data structure that holds are probabilities\n","        \"\"\"\n","        # Get X's columns\n","        col_names = X.columns.tolist()\n","        # Iterate over all columns in 'X'\n","        for col_name in col_names:\n","            # Get unique values for that column\n","            uniques = list(X[col_name].unique())\n","            # Iterate over all the unique values of current attribute\n","            for attrib_value in uniques:\n","                # Create column name by concatenating 'col_name' and 'attrib_value'\n","                new_col_name = str(col_name + '_' + attrib_value)\n","                # Append new column\n","                self.word_proba[new_col_name] = None\n","              \n","        # Get class column label\n","        y_col_name = y.columns[0]\n","        # Get unique values for class label column\n","        y_uniques = y[y_col_name].unique()\n","        # Populate list of null values equal to the number of columns in 'self.word_proba'\n","        dummy_values = []\n","        for i in range(len(self.word_proba.columns)):\n","            dummy_values.append(0)\n","        # Create list of Series Pandas objects\n","        list_of_series = []\n","        # Iterate over unique values in class label column\n","        for unique in y_uniques:\n","            # Create Series object\n","            series = pd.Series(dummy_values, index=self.word_proba.columns)\n","            # Add 'series' to list of Series objects\n","            list_of_series.append(series)\n","        # Append the k number of unique class values to 'self.word_proba' data structure\n","        self.word_proba = self.word_proba.append(list_of_series, ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zzHafjj3VpXt"},"source":["# Fit the model to some data\n","nb = NaiveBayes()\n","nb.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ymILT_DkVpX4"},"source":["# Visual display of training phase of the model\n","nb.word_proba.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wHfd2l38VpX5"},"source":["# Output a confusion matrix. Compute accuracy, precision, recall and obtain an AUC plot of the classifier\n","\n","# Get list of predictions\n","preds = nb.predict(X_test)\n","# Get 2D Matrix of probabilities of predictions\n","pred_probas = nb.predict_probas(X_test)\n","# Convert to numpy.ndarray\n","np_pred_probas = np.array(pred_probas, np.float64)\n","# Get spam probabilities\n","pos_probas = np_pred_probas[:, 1]\n","# Get confusion matrix, precision, and recall\n","true_neg, true_pos, false_neg, false_pos, confusion_matrix = nb.get_metrics(preds, y_test)\n","print(f'True negatives: {true_neg}')\n","print(f'True positive: {true_pos}')\n","print(f'False negatives: {false_neg}')\n","print(f'False positive: {false_pos}')\n","print(f'Confusion matrix: {confusion_matrix}')\n","print('--------------------------------------')\n","print(f'Accuracy: {(true_neg + true_pos)/(true_neg + true_pos + false_neg + false_pos)}')\n","print(f'Precision: {(true_pos)/(true_pos + false_pos)}')\n","print(f'Recall: {(true_pos)/(true_pos + false_neg)}')\n","print('--------------------------------------')\n","\n","# Plot the two AUCs\n","nb_fpr, nb_tpr, nb_thresholds = roc_curve(y_test, pos_probas)\n","plot_roc_curve(nb_fpr, nb_tpr, \"Naive Bayes\")"],"execution_count":null,"outputs":[]}]}